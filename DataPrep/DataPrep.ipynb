{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ3oA2Si7BJK",
        "outputId": "43a75aeb-d851-4e34-f431-b2f7af13fd4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting convokit\n",
            "  Downloading convokit-3.0.0.tar.gz (183 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/183.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.2/183.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from convokit) (3.8.0)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from convokit) (2.2.2)\n",
            "Collecting msgpack-numpy>=0.4.3.2 (from convokit)\n",
            "  Downloading msgpack_numpy-0.4.8-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: spacy>=2.3.5 in /usr/local/lib/python3.10/dist-packages (from convokit) (3.7.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from convokit) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from convokit) (1.5.2)\n",
            "Requirement already satisfied: nltk>=3.4 in /usr/local/lib/python3.10/dist-packages (from convokit) (3.8.1)\n",
            "Collecting dill>=0.2.9 (from convokit)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from convokit) (1.4.2)\n",
            "Collecting clean-text>=0.6.0 (from convokit)\n",
            "  Downloading clean_text-0.6.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting unidecode>=1.1.1 (from convokit)\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from convokit) (4.66.6)\n",
            "Collecting pymongo>=4.0 (from convokit)\n",
            "  Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from convokit) (6.0.2)\n",
            "Collecting dnspython>=1.16.0 (from convokit)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting emoji<2.0.0,>=1.0.0 (from clean-text>=0.6.0->convokit)\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy<7.0,>=6.0 (from clean-text>=0.6.0->convokit)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (2.8.2)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from msgpack-numpy>=0.4.3.2->convokit) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4->convokit) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4->convokit) (2024.9.11)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->convokit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->convokit) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->convokit) (3.5.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (0.12.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (3.4.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy<7.0,>=6.0->clean-text>=0.6.0->convokit) (0.2.13)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=2.3.5->convokit) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.3.5->convokit) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.3.5->convokit) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.3.5->convokit) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->convokit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=2.3.5->convokit) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy>=2.3.5->convokit) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=2.3.5->convokit) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=2.3.5->convokit) (13.9.3)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.3.5->convokit) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.3.5->convokit) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=2.3.5->convokit) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=2.3.5->convokit) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.3.5->convokit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.3.5->convokit) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=2.3.5->convokit) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.3.5->convokit) (0.1.2)\n",
            "Downloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
            "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgpack_numpy-0.4.8-py2.py3-none-any.whl (6.9 kB)\n",
            "Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: convokit, emoji\n",
            "  Building wheel for convokit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for convokit: filename=convokit-3.0.0-py3-none-any.whl size=216707 sha256=76093a860c2e98d9b3add03c35663db7e7f1da3d3e74732cfd94f48d3f90ea1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/89/8c/2677fdb888588b6f93cb6ac86bdfb020f1f1c33e0d5525b231\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171033 sha256=433d3d8e181a3f7181b6202253c77bcec2aa47ead9d02b8331c1c7563c70d4ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n",
            "Successfully built convokit emoji\n",
            "Installing collected packages: emoji, unidecode, msgpack-numpy, ftfy, dnspython, dill, pymongo, clean-text, convokit\n",
            "Successfully installed clean-text-0.6.0 convokit-3.0.0 dill-0.3.9 dnspython-2.7.0 emoji-1.7.0 ftfy-6.3.1 msgpack-numpy-0.4.8 pymongo-4.10.1 unidecode-1.3.8\n"
          ]
        }
      ],
      "source": [
        "pip install convokit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import convokit"
      ],
      "metadata": {
        "id": "GHJoKEHG8pTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Friends Corpus\n",
        "corpus = convokit.Corpus(filename=convokit.download('friends-corpus'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_G4uxbL-pHy",
        "outputId": "0ed5a911-0d55-432e-8ce4-4f76ec6ee0c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading friends-corpus to /root/.convokit/downloads/friends-corpus\n",
            "Downloading friends-corpus from http://zissou.infosci.cornell.edu/convokit/datasets/friends-corpus/friends-corpus.zip (6.1MB)... Done\n",
            "No configuration file found at /root/.convokit/config.yml; writing with contents: \n",
            "# Default Backend Parameters\n",
            "db_host: localhost:27017\n",
            "data_directory: ~/.convokit/saved-corpora\n",
            "default_backend: mem\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find Chandler's speaker object\n",
        "chandler_speaker = None\n",
        "for speaker in corpus.iter_speakers():\n",
        "    print(speaker)\n",
        "    if speaker.id == \"Chandler Bing\":\n",
        "        chandler_speaker = speaker\n",
        "        print(chandler_speaker.print_speaker_stats())\n",
        "        break\n",
        "\n",
        "if chandler_speaker is None:\n",
        "    raise ValueError(\"Chandler Bing not found in the corpus\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpANNYQO-1dh",
        "outputId": "7c5c455f-535e-4f7d-9644-d1ccf6736dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speaker(id: 'Monica Geller', vectors: [], meta: ConvoKitMeta({}))\n",
            "Speaker(id: 'Joey Tribbiani', vectors: [], meta: ConvoKitMeta({}))\n",
            "Speaker(id: 'Chandler Bing', vectors: [], meta: ConvoKitMeta({}))\n",
            "Number of Utterances: 8568\n",
            "Number of Conversations: 1513\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Chandler's character ID in the dataset\n",
        "character_name = \"Chandler Bing\"\n",
        "\n",
        "# Extract conversations where Chandler is speaking\n",
        "# chandler_conersations = []\n",
        "# for conv in chandler_speaker.iter_conversations():\n",
        "#     chandler_conversations.append({\n",
        "#         \"conversation_id\": conv.id,\n",
        "#         \"utterance_id\": utt.id,\n",
        "#         \"text\": utt.text,\n",
        "#         \"reply_to\": utt.reply_to,\n",
        "#         \"speaker\": utt.speaker.name\n",
        "#     })\n",
        "def getUttReplyTo(utt):\n",
        "    if utt.reply_to == None:\n",
        "        return utt.speaker.id\n",
        "    else:\n",
        "        return corpus.get_utterance(utt.reply_to).speaker.id\n",
        "\n",
        "chandler_utterances = []\n",
        "for utt in chandler_speaker.iter_utterances():\n",
        "      chandler_utterances.append({\n",
        "          \"utterance_id\": utt.id,\n",
        "          \"text\": utt.text,\n",
        "          \"reply_to\": getUttReplyTo(utt),\n",
        "          \"speaker\": utt.speaker.id\n",
        "      })\n",
        "\n",
        "print(chandler_utterances[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLLZUfCh8fZz",
        "outputId": "8e3890f5-cf47-4af6-f765-9d64e4a04604"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'utterance_id': 's01_e01_c01_u003', 'text': 'All right Joey, be nice. So does he have a hump? A hump and a hairpiece?', 'reply_to': 'Joey Tribbiani', 'speaker': 'Chandler Bing'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IvZTPfCViRTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert to DataFrame for easier manipulation\n",
        "chandler_df = pd.DataFrame(chandler_utterances)\n",
        "print(chandler_df)\n",
        "# Merge with previous utterance if `reply_to` is available\n",
        "# This will create conversational pairs (prompt, response) for training\n",
        "paired_data = []\n",
        "for _, row in chandler_df.iterrows():\n",
        "    if row['reply_to']:\n",
        "        # Find the previous utterance by ID\n",
        "        previous_utt = chandler_df[chandler_df['utterance_id'] == row['reply_to']]\n",
        "        if not previous_utt.empty:\n",
        "            paired_data.append({\n",
        "                \"prompt\": previous_utt.iloc[0]['text'],\n",
        "                \"response\": row['text']\n",
        "            })\n",
        "\n",
        "# Convert paired data to DataFrame and save\n",
        "paired_df = pd.DataFrame(paired_data)\n",
        "\n",
        "# Save the structured data to a CSV for training\n",
        "paired_df.to_csv(\"chandler_dialogues.csv\", index=False)\n",
        "print(\"Data saved to chandler_dialogues.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rwHVSR9qdby",
        "outputId": "d03d9c25-6a0a-47b1-ede1-f884127db51b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          utterance_id                                               text  \\\n",
            "0     s01_e01_c01_u003  All right Joey, be nice. So does he have a hum...   \n",
            "1     s01_e01_c01_u008                          Sounds like a date to me.   \n",
            "2     s01_e01_c01_u010  Alright, so I'm back in high school, I'm stand...   \n",
            "3     s01_e01_c01_u012  Then I look down, and I realize there's a phon...   \n",
            "4     s01_e01_c01_u014                                      That's right.   \n",
            "...                ...                                                ...   \n",
            "8563  s10_e18_c09_u011                                      Where's Ross?   \n",
            "8564  s10_e18_c11_u006  Look around, you guys. This was your first hom...   \n",
            "8565  s10_e18_c11_u013                                          Oh, okay.   \n",
            "8566  s10_e18_c11_u017                            Oh, it's gonna be okay.   \n",
            "8567  s10_e18_c11_u021                                       Sure. Where?   \n",
            "\n",
            "             reply_to        speaker  \n",
            "0      Joey Tribbiani  Chandler Bing  \n",
            "1       Monica Geller  Chandler Bing  \n",
            "2     TRANSCRIPT_NOTE  Chandler Bing  \n",
            "3               #ALL#  Chandler Bing  \n",
            "4      Joey Tribbiani  Chandler Bing  \n",
            "...               ...            ...  \n",
            "8563    Phoebe Buffay  Chandler Bing  \n",
            "8564   Joey Tribbiani  Chandler Bing  \n",
            "8565    Monica Geller  Chandler Bing  \n",
            "8566    Monica Geller  Chandler Bing  \n",
            "8567     Rachel Green  Chandler Bing  \n",
            "\n",
            "[8568 rows x 4 columns]\n",
            "Data saved to chandler_dialogues.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for conv in chandler_speaker.iter_conversations():\n",
        "    dialogue_sequence = []\n",
        "    for utt in conv.iter_utterances():\n",
        "        # Track the entire conversation flow, but tag Chandler’s lines\n",
        "        if utt.speaker.id == chandler_speaker.id:\n",
        "            dialogue_sequence.append(f\"Chandler: {utt.text} \\n\")\n",
        "        else:\n",
        "            dialogue_sequence.append(f\"{utt.speaker.id}: {utt.text}\")"
      ],
      "metadata": {
        "id": "to758rCYiTmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chandler_utterances = []\n",
        "for utt in chandler_speaker.iter_utterances():\n",
        "    dialogue_sequence = []\n",
        "    if utt.reply_to != None:\n",
        "        replyto_utt = corpus.get_utterance(utt.reply_to)\n",
        "        if replyto_utt.speaker.id != 'TRANSCRIPT_NOTE':\n",
        "           # dialogue_sequence.append(f\"{replyto_utt.speaker.id}: {replyto_utt.text};\\n {utt.speaker.id}: {utt.text} \\n\")\n",
        "            chandler_utterances.append({\n",
        "                \"text\": utt.text,\n",
        "                \"reply_to_speaker\": replyto_utt.speaker.id,\n",
        "                \"reply_to_text\": replyto_utt.text\n",
        "            })\n",
        "            #if len(dialogue_sequence[0]) > 500:\n",
        "            #    print(dialogue_sequence)\n",
        "\n",
        "chandler_df = pd.DataFrame(chandler_utterances)\n",
        "\n",
        "# Print the first few rows to verify\n",
        "print(chandler_df.head())\n",
        "\n",
        "# Save the structured data to a CSV for training\n",
        "chandler_df.to_csv(\"chandler_dialogues.csv\", index=False)\n",
        "print(\"Data saved to chandler_dialogues.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2yyK6_LiU0n",
        "outputId": "6fee6c30-fc77-43c9-ede9-f701ba62ea1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text reply_to_speaker  \\\n",
            "0  All right Joey, be nice. So does he have a hum...   Joey Tribbiani   \n",
            "1                          Sounds like a date to me.    Monica Geller   \n",
            "2  Then I look down, and I realize there's a phon...            #ALL#   \n",
            "3                                      That's right.   Joey Tribbiani   \n",
            "4  All of a sudden, the phone starts to ring. Now...    Phoebe Buffay   \n",
            "\n",
            "                                       reply_to_text  \n",
            "0  C'mon, you're going out with the guy! There's ...  \n",
            "1  Okay, everybody relax. This is not even a date...  \n",
            "2                          Oh, yeah. Had that dream.  \n",
            "3                                     Instead of...?  \n",
            "4                                                No.  \n",
            "Data saved to chandler_dialogues.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model dataset specific for phi3 now, but later conisder making it json so templates can be applied\n",
        "import json\n",
        "\n",
        "#system_message = {\n",
        "#    \"role\": \"system\",\n",
        "#    \"content\": \"You are Joey Tribbiani from the TV show Friends. Respond to questions and engage in conversations in his signature style.\"\n",
        "#}\n",
        "conversations = []\n",
        "for conv in chandler_speaker.iter_conversations():\n",
        "    conversation = \"\"\n",
        "    #dialogue.append({\"role\": \"System\", \"text\": \"You are Chandler\"})\n",
        "    for utt in conv.iter_utterances():\n",
        "        if utt.speaker.id == character_name:\n",
        "            conversation += f\"<|assistant|>{utt.text}\\n\"\n",
        "        else:\n",
        "        if utt.speaker.id != 'TRANSCRIPT_NOTE':\n",
        "\n",
        "            conversation += f\"{utt.speaker.id}: {utt.text}\\n\"\n",
        "    conversations.append(conversation)\n",
        "\n",
        "chandler_utterances = []\n",
        "for utt in chandler_speaker.iter_utterances():\n",
        "    dialogue_sequence = []\n",
        "    if utt.reply_to != None:\n",
        "        replyto_utt = corpus.get_utterance(utt.reply_to)\n",
        "        if replyto_utt.speaker.id != 'TRANSCRIPT_NOTE':\n",
        "           # dialogue_sequence.append(f\"{replyto_utt.speaker.id}: {replyto_utt.text};\\n {utt.speaker.id}: {utt.text} \\n\")\n",
        "            chandler_utterances.append({\n",
        "                \"text\": utt.text,\n",
        "                \"reply_to_speaker\": replyto_utt.speaker.id,\n",
        "                \"reply_to_text\": replyto_utt.text\n",
        "            })\n",
        "            #if len(dialogue_sequence[0]) > 500:\n",
        "            #    print(dialogue_sequence)\n",
        "\n",
        "chandler_df = pd.DataFrame(chandler_utterances)\n",
        "\n",
        "# Print the first few rows to verify\n",
        "print(chandler_df.head())\n",
        "\n",
        "# Save the structured data to a CSV for training\n",
        "chandler_df.to_csv(\"chandler_dialogues.csv\", index=False)\n",
        "print(\"Data saved to chandler_dialogues.csv\")\n",
        "\n",
        "\n",
        "\n",
        "from convokit import Corpus, download\n",
        "\n",
        "# Load the Convokit Corpus\n",
        "corpus = Corpus(filename=download(\"friends-corpus\"))\n",
        "\n",
        "# Define a system message for the assistant (e.g., Joey's persona)\n",
        "system_message = {\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"You are Joey Tribbiani from the TV show Friends. Respond to questions and engage in conversations in his signature style.\"\n",
        "}\n",
        "\n",
        "# Prepare the formatted data for JSON\n",
        "formatted_data = []\n",
        "\n",
        "for conv in corpus.iter_conversations():\n",
        "    messages = [system_message]\n",
        "\n",
        "    # Iterate through the utterances (turns) in the conversation\n",
        "    for utt in conv.iter_utterances():\n",
        "        # Assign \"user\" role for other speakers and \"assistant\" role for Joey\n",
        "        role = \"user\" if utt.speaker.id != \"Joey\" else \"assistant\"\n",
        "        messages.append({\n",
        "            \"role\": role,\n",
        "            \"content\": utt.text\n",
        "        })\n",
        "\n",
        "    # Add the conversation to the dataset\n",
        "    formatted_data.append({\"messages\": messages})\n",
        "\n",
        "# Save the formatted dataset to a JSON file\n",
        "with open(\"formatted_conversations.json\", \"w\") as f:\n",
        "    json.dump(formatted_data, f, indent=4)\n",
        "\n",
        "print(f\"Saved {len(formatted_data)} conversations to 'formatted_conversations.json'\")\n"
      ],
      "metadata": {
        "id": "I3EPV__hWWJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOdlTv8rjNJr",
        "outputId": "5b2ab278-2d95-4f50-828c-3fe256f0724d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ]
}